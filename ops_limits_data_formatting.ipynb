{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joey\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\joey\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "c:\\users\\joey\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# k-means clustering\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VERTIPORTS = 160\n",
    "NUM_VERTIHUBS = 64\n",
    "MINUTES_OF_DATA = 1\n",
    "USES_ADDITIONAL_VERTHUBS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Realtime/OpsLimits/zone17_lat_long.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(data, num_clusters):\n",
    "    kmeans = KMeans(n_clusters=num_clusters, init='k-means++', max_iter=300, n_init=10, random_state=0).fit(data[:,[0,1]])\n",
    "    labels = kmeans.labels_\n",
    "    plt.scatter(data[:,0], data[:,1], c=['tab:blue' for i in labels], alpha=.5, label='Zone', s=20)\n",
    "    plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1],s=50,c='tab:orange', label='Vertiport - Centroid')\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.legend()\n",
    "    plt.title(\"K-Means Zone Clusters\")\n",
    "    plt.savefig('data/Realtime/OpsLimits/zones_to_towers_' + str(NUM_VERTIHUBS) + '.png', dpi=216)\n",
    "    plt.show()\n",
    "    return kmeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "formatted_df = copy.deepcopy(df)\n",
    "formatted_df['color'] = [float(0.5) for i in range(len(formatted_df['lat']))]\n",
    "formatted_df = formatted_df[['long','lat','color']].to_numpy()\n",
    "kmeans = k_means(formatted_df, NUM_VERTIPORTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_vertihub(vertihub_to_duplicate: int, new_vertihub_number : int, num_duplications : int, vertihubs_to_vertiports, column_header : str):\n",
    "    # find the vertiports associated with the original vertihub\n",
    "    vertiports = []\n",
    "    for idx, vertihub in enumerate(vertihubs_to_vertiports['vertihub_0']):\n",
    "        if vertihub == vertihub_to_duplicate:\n",
    "            vertiports.append(idx)\n",
    "    \n",
    "    for i in range(num_duplications):\n",
    "        for vertiport in vertiports:\n",
    "            vertihubs_to_vertiports[column_header + str(i+1)][vertiport] = new_vertihub_number\n",
    "            vertihubs_to_vertiports['num_vertihubs'][vertiport] += 1\n",
    "        new_vertihub_number += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cluster centers = tower, cluster these towers for determing rendezvous points\n",
    "tower_locations = kmeans.cluster_centers_\n",
    "\n",
    "vertihubs_to_vertiports = pd.DataFrame()\n",
    "vertihubs_to_vertiports['vertiport'] = [i for i in range(NUM_VERTIPORTS)]\n",
    "\n",
    "vertihubs_to_vertiports['long'] = copy.deepcopy(tower_locations[:,0])\n",
    "vertihubs_to_vertiports['lat'] = copy.deepcopy(tower_locations[:,1])\n",
    "vertihubs_to_vertiports['color'] = [.5 for i in range(len(vertihubs_to_vertiports['lat']))]\n",
    "\n",
    "tower_locations_formatted = vertihubs_to_vertiports[['long','lat','color']].to_numpy()\n",
    "\n",
    "vertiport_kmeans = k_means(tower_locations_formatted, NUM_VERTIHUBS)\n",
    "vertihubs_to_vertiports['num_vertihubs'] = [1 for i in range(NUM_VERTIPORTS)]\n",
    "vertihubs_to_vertiports['vertihub_0'] = vertiport_kmeans.labels_\n",
    "vertihubs_to_vertiports.drop(columns='color', inplace=True)\n",
    "\n",
    "num_vertihub_columns = 1 #kind of a global variable. need to use this when assigning requests to vertihubs\n",
    "total_additional_vertihubs = 0  # same as above - need this for saving the request mapping csv\n",
    "if USES_ADDITIONAL_VERTHUBS:\n",
    "    vertihubs_to_duplicate = [(5,1), (11, 1), (1, 1), (6, 1)] # (vertihub name, num times to dupe)\n",
    "    num_vertihub_columns += max([i[1] for i in vertihubs_to_duplicate])\n",
    "\n",
    "    # prepping the columns for storing additional vertihubs\n",
    "    column_header = 'vertihub_'\n",
    "    for i in range(1, num_vertihub_columns): \n",
    "        curr_header = column_header + str(i)\n",
    "        vertihubs_to_vertiports[curr_header] = [-1 for i in range(NUM_VERTIPORTS)]\n",
    "    \n",
    "    total_additional_vertihubs = sum([i[1] for i in vertihubs_to_duplicate])\n",
    "    total_vertihubs = NUM_VERTIHUBS\n",
    "    for vertihub, num_duplications in vertihubs_to_duplicate:\n",
    "        duplicate_vertihub(vertihub, total_vertihubs, num_duplications, vertihubs_to_vertiports, column_header)\n",
    "        total_vertihubs += num_duplications\n",
    "        \n",
    "    vertihubs_to_vertiports.to_csv(\n",
    "        'data/Realtime/OpsLimits/vertiports_' + \n",
    "        str(NUM_VERTIHUBS + total_additional_vertihubs) + \n",
    "        '_additional_vhubs_' + \n",
    "        str(total_additional_vertihubs) + '.csv',\n",
    "        index=False)\n",
    "else:\n",
    "    vertihubs_to_vertiports.to_csv('data/Realtime/OpsLimits/vertiports_' + str(NUM_VERTIHUBS) + '.csv', index=False)\n",
    "# these are actually vertihubs (orange) and vertiports (blue)\n",
    "vertihubs_to_vertiports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that each zone is assigned to a vertiport, lets change our flights from zone->zone to vertiport->vertiport\n",
    "\n",
    "# NOTE: THIS DATA SET IS NOT INCLUDED WITH THE REPOSITORY AS IT IS A LARGE FILE. Please contact me (joeymuffoletto10@gmail.com) or Dr. Natasha Neogi (natasha.a.neogi@nasa.gov)\n",
    "trips_from_work = pd.read_csv('data/Realtime/OpsLimits/commute_trips_fr_work_hhincome_all_chicago_matlab.csv')\n",
    "time = trips_from_work['time']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "TIME_RANGE_START = datetime.time(15,0,0)\n",
    "TIME_RANGE_END = datetime.time(15,MINUTES_OF_DATA, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert to datetime.time objects\n",
    "trips_between_start_end = [] \n",
    "for row in trips_from_work.itertuples(index=False):\n",
    "    as_datetime = datetime.datetime.fromisoformat(row[0]).time()\n",
    "    if as_datetime >= TIME_RANGE_START and as_datetime <= TIME_RANGE_END:\n",
    "        trips_between_start_end.append((as_datetime, row[1], row[2], \n",
    "                                        row[3], row[4]))\n",
    "print(trips_between_start_end[0])\n",
    "print(len(trips_between_start_end))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import cos, asin, sqrt, pi\n",
    "\n",
    "# def dist(x1, y1, x2, y2):\n",
    "#     return math.sqrt((y2-y1)**(y2-y1) + (x2-x1)**(x2-x1))\n",
    "def ll_distance(lat1, lon1, lat2, lon2):\n",
    "    p = pi/180\n",
    "    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p) * cos(lat2*p) * (1-cos((lon2-lon1)*p))/2\n",
    "    return 12742 * asin(sqrt(a)) #2*R*asin...   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for these trips, convert their longlat origin and destination coordinate to the nearest tower\n",
    "\n",
    "tower_locations = kmeans.cluster_centers_\n",
    "# print(tower_locations)\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:red', 'tab:green', 'tab:purple', 'tab:brown', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "color_map = {i : color for i, color in enumerate(colors)}\n",
    "\n",
    "frame = pd.DataFrame()\n",
    "frame['long'] = copy.deepcopy(tower_locations[:,0])\n",
    "frame['lat'] = copy.deepcopy(tower_locations[:,1])\n",
    "frame['color'] = [.5 for i in range(len(frame['lat']))]\n",
    "\n",
    "tower_to_rendezvous = frame\n",
    "tower_to_rendezvous['tower'] = [i for i in range(NUM_VERTIPORTS)] \n",
    "\n",
    "formatted_trips = []\n",
    "min_time = datetime.datetime.combine(datetime.date.min, min(trips_between_start_end)[0])\n",
    "vertiport_trip_index = [0 for i in range(NUM_VERTIPORTS)] # default to 0 (vertihub_0). \n",
    "for trip in trips_between_start_end:\n",
    "    time, origin_lat, origin_long, dest_lat, dest_long = trip\n",
    "    origin = min([(ll_distance(origin_lat, origin_long, other_lat, other_long), tower) \n",
    "                  for other_lat, other_long, tower in \n",
    "                  zip(tower_to_rendezvous['lat'],\n",
    "                    tower_to_rendezvous['long'],\n",
    "                     tower_to_rendezvous['tower']\n",
    "                     )\n",
    "                 ])\n",
    "    destination = min([(ll_distance(dest_lat, dest_long, other_lat, other_long), tower) \n",
    "                  for other_lat, other_long, tower in \n",
    "                  zip(tower_to_rendezvous['lat'],\n",
    "                    tower_to_rendezvous['long'],\n",
    "                     tower_to_rendezvous['tower']\n",
    "                     )\n",
    "                 ])\n",
    "    normalized_time_in_seconds = (datetime.datetime.combine(datetime.date.min, time) - min_time).seconds # each time step is one second\n",
    "    origin_vertiport = origin[1]\n",
    "    destination_vertiport = destination[1]\n",
    "    origin_vertihub = vertihubs_to_vertiports['vertihub_0'][origin_vertiport] #NOTE: the origin will never be one of the \"additional\" vertihubs -> this doesn't matter...yet\n",
    "      #NOTE: very weird. basically, later on when you use the trips, you end up dropping ones which have the same origin and destination vertihubs. Lets do this right now so that we don't end up with garbage date that we have to deal with later\n",
    "    # this fix accommadates for additional vertihubs\n",
    "    #NOTE: now including trips that start and end in the same vertihub (3/8/22)\n",
    "#     if origin_vertihub == vertihubs_to_vertiports['vertihub_0'][destination_vertiport]:\n",
    "#       continue # dont add the trip!\n",
    "\n",
    "    # if vertihubs_to_vertiports['vertihub_' + str(vertiport_trip_index[destination_vertiport])][destination_vertiport] == -1:\n",
    "    #   vertiport_trip_index[destination_vertiport] = 0\n",
    "    assert(vertihubs_to_vertiports['vertihub_' + str(vertiport_trip_index[destination_vertiport])][destination_vertiport] != -1)\n",
    "    destination_vertihub = vertihubs_to_vertiports['vertihub_' + str(vertiport_trip_index[destination_vertiport])][destination_vertiport]\n",
    "\n",
    "    vertiport_trip_index[destination_vertiport] = (vertiport_trip_index[destination_vertiport] + 1)%vertihubs_to_vertiports['num_vertihubs'][destination_vertiport] # the modulo value (after the percent sign) is the number of vertihubs that this port is mapped to. Default is 1\n",
    "\n",
    "    \n",
    "\n",
    "    formatted_trips.append((normalized_time_in_seconds, origin_vertihub, origin_vertiport, destination_vertihub, destination_vertiport)) # seconds from start time of simulation\n",
    "# print (formatted_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = pd.DataFrame(formatted_trips, columns=['Time', 'OriginVertihub','OriginVertiport', 'DestinationVertihub', 'DestinationVertiport'])\n",
    "path = 'data/Realtime/OpsLimits/trips_' + str(NUM_VERTIHUBS+total_additional_vertihubs) + '_minutes-' + str(MINUTES_OF_DATA)\n",
    "if USES_ADDITIONAL_VERTHUBS:\n",
    "    trips_df.to_csv(path + '_additional_vhubs_' + str(total_additional_vertihubs) + '.csv', index=False)\n",
    "else:\n",
    "    trips_df.to_csv(path + '.csv', index=False)\n",
    "trips_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "062ca1eb9d1cfd384bf82597815a492c2555446b36a8d1e8dd41731a23537749"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
